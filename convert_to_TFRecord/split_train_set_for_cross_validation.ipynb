{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fHv0oWaHgtV"
   },
   "source": [
    "This notebook shows how to split the train set into k partitions to perform crossvalidation.\n",
    "\n",
    "Before running this notebook, make sure the file `train_tfrecords0.record` is located in `hyperspectral-cnn-soil-estimation/dataset`. If the file is not present, follow the instructions in the notebook `convert_dataset_to_TFRecords.ipynb` to create one or run the following cell to download our ready-to-use dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h0KarWJtIjpm"
   },
   "outputs": [],
   "source": [
    "%cd\n",
    "%cd hyperspectral-cnn-soil-estimation/dataset\n",
    "\n",
    "#Challenge train set already converted to TFRecord file format\n",
    "!gdown https://drive.google.com/uc?id=1wD3vKqKEFh6OfrfLNtOENF-lbe4auQDb\n",
    "\n",
    "%cd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-66cVIxnMCCr"
   },
   "source": [
    "# Load full train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2D5NU0ZSJ3Xf"
   },
   "source": [
    "Navigate to the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1679238243123,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "OE9gS6QyJ2zt",
    "outputId": "2c8255a1-4748-41a9-fe27-3b43ed93c60c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/microsat\n",
      "/home/microsat/hyperspectral-cnn-soil-estimation\n"
     ]
    }
   ],
   "source": [
    "%cd\n",
    "%cd hyperspectral-cnn-soil-estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KfsHjNylePr7"
   },
   "source": [
    "Define dataset path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1679238246350,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "o2h0RGrVPVIe"
   },
   "outputs": [],
   "source": [
    "train_set_path = 'dataset/train_tfrecords0.record'\n",
    "output_path='dataset/train_cv_split_{}.record'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w8RtTSEpMQED"
   },
   "source": [
    "Import required libraries and load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WQkFdqz3H_rO"
   },
   "outputs": [],
   "source": [
    "import os, logging\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "from dataset_processing import *\n",
    "import tensorflow as tf\n",
    "\n",
    "train_data=load_tf_records(train_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNvweUXsGtbV"
   },
   "source": [
    "# Shuffle and split training dataset into k partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3521,
     "status": "ok",
     "timestamp": 1679238632720,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "rHZpQwWiGssy"
   },
   "outputs": [],
   "source": [
    "number_of_partitions = 5\n",
    "num_images = len(list(train_data))\n",
    "\n",
    "dataset = train_data.shuffle(num_images, seed=958).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3783,
     "status": "ok",
     "timestamp": 1679237474192,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "8guFAOB_Lk6x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing  dataset/train_cv_split_0.record\n",
      "Writing  dataset/train_cv_split_1.record\n",
      "Writing  dataset/train_cv_split_2.record\n",
      "Writing  dataset/train_cv_split_3.record\n",
      "Writing  dataset/train_cv_split_4.record\n",
      "\n",
      "Writing completed\n"
     ]
    }
   ],
   "source": [
    "to_skip = 0\n",
    "to_take = num_images//number_of_partitions\n",
    "\n",
    "# iterate over dataset so that it is cached and the new resulting sets do not have overlapping elements\n",
    "for i in dataset:  \n",
    "    pass\n",
    "\n",
    "for i in range(number_of_partitions):\n",
    "    writer = tf.data.experimental.TFRecordWriter(output_path.format(i))\n",
    "\n",
    "    if i<number_of_partitions-1:\n",
    "      print('Writing ', output_path.format(i))\n",
    "      writer.write(dataset.skip(to_skip).take(to_take))\n",
    "    else:\n",
    "      print('Writing ', output_path.format(i))\n",
    "      writer.write(dataset.skip(to_skip))\n",
    "    \n",
    "    to_skip = to_skip+to_take\n",
    "    \n",
    "print()\n",
    "print('Writing completed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itiiTujWYwuT"
   },
   "source": [
    "# Validate partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXcnQ9jkcbMK"
   },
   "source": [
    "Validation will be performed on filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1679238696275,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "eee8WHasZTFl"
   },
   "outputs": [],
   "source": [
    "def get_filename(example_proto):\n",
    "    '''Function to get the filename of each record'''\n",
    "    features=tf.io.parse_single_example(example_proto, tf_records_file_features_description_train())\n",
    "\n",
    "    filename=features['image/filename']\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QW_Rccwby6f"
   },
   "source": [
    "List tfrecord partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1679239274014,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "6mHeu2GNXaU-"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = 'dataset'\n",
    "file_list = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.startswith(\"train_cv_split\"):\n",
    "        file_list.append(file)\n",
    "\n",
    "file_list=sorted(file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOsrqlzxb18G"
   },
   "source": [
    "Check that 1732 images are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2261,
     "status": "ok",
     "timestamp": 1679239287996,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "Esp0DClxXepY",
    "outputId": "eaae9e41-2cb5-428d-d9e4-946d6bc5c390"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images in parition  0 :  346\n",
      "images in parition  1 :  346\n",
      "images in parition  2 :  346\n",
      "images in parition  3 :  346\n",
      "images in parition  4 :  348\n",
      "total number of images:  1732\n"
     ]
    }
   ],
   "source": [
    "i=-1\n",
    "for file in file_list:\n",
    "  i+=1\n",
    "  if i==0:\n",
    "    check_partitions = load_tf_records('dataset/'+file)\n",
    "    print('images in parition ', i, ': ', len(list(load_tf_records('dataset/'+file))))\n",
    "  else:\n",
    "    check_partitions=check_partitions.concatenate(load_tf_records('dataset/'+file))\n",
    "    print('images in parition ', i, ': ', len(list(load_tf_records('dataset/'+file))))\n",
    "\n",
    "print('total number of images: ', len(list(check_partitions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVDyOzpAb-9r"
   },
   "source": [
    "Compare the list of filenames from the original tfrecord file and the list of filenames from the partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1059,
     "status": "ok",
     "timestamp": 1679239292011,
     "user": {
      "displayName": "Sistemi Spaziali",
      "userId": "03880471792653564924"
     },
     "user_tz": -60
    },
    "id": "ytiNwr8iZvI6",
    "outputId": "349423b8-4cb6-4113-ae3a-d658280164f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two lists have exactly the same elements.\n"
     ]
    }
   ],
   "source": [
    "check_partitions_filenames = check_partitions.map(get_filename)\n",
    "check_full_filenames = dataset.map(get_filename)\n",
    "\n",
    "tfrecords_partitions_filenames = []\n",
    "tfrecords_original_filenames = []\n",
    "\n",
    "for record in check_partitions_filenames:\n",
    "  tfrecords_partitions_filenames.append(record.numpy().decode())\n",
    "\n",
    "for record in check_full_filenames:\n",
    "  tfrecords_original_filenames.append(record.numpy().decode())\n",
    "\n",
    "if sorted(tfrecords_partitions_filenames) == sorted(tfrecords_original_filenames):\n",
    "    print(\"The two lists have exactly the same elements.\")\n",
    "else:\n",
    "    print(\"The two lists do not have exactly the same elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
